\section{Continuity of system performance with respect to lead time}

In the experiment, we considered two lead times. It is an interesting question
to ask whether the system's performance changes continuously with respect to
the lead time. Here we give a proof for the following similar but simplified setting:
\begin{itemize}
\item There are $k$ sites, each with one machine.
\item There are $n$ patients. Patient $i$ has appointment time $a_i$
      and will arrive punctually.
\item The service duration $d_i$ of patient $i$ follows exponential
      distribution $Exp(\mu_i)$ with mean $\frac{1}{\mu_i}$.
\end{itemize}
For technical reason, we will first make a small change to our instance:
we will use a new appointment time $\tilde a_i = a_i + \delta u_i$,
where $\delta$ is a small constant and each $u_i$ is a uniform
random variable on $[-1,1]$. Now, all of the appointment times
are different almost surely.

The system will follow join-shortest-queue policy with lead time $l$.
For each patient $i$, there is a decision epoch at time $\tilde a_i - l$.
Let $P_{ij}(l)$ be the set of patients that are assigned to site $j$,
but have not completed their scans.
The system will calculate, for each site $j$, the time $C_{ij}(l)$ to finish patients $P_{ij}(l)$,
assuming that the scans will take expected duration. The system
will assign patient $i$ to the site with earliest $C_{ij}(l)$.
If there is a tie, the patient will be assigned to the site with
lower number.

Let sample path $\omega$ includes all of the randomness of $u_i$ and $d_i$,
and let $X(l)$ be the random total waiting time of all of the patients.
We will prove the following theorem.

\begin{thm}
  $\E[X(l)]$ is continuous with respect to lead time $l \ge 0$.
\end{thm}

\begin{proof}
Number all of the patients from $1$ to $n$ in non-decreasing order of $\tilde a_i$.
Note that the waiting time for any patient $i$ can be bounded
by the sum of scan duration of previous patients $\sum_{i' < i} d_{i'}$.
This implies that the total waiting time $X(l+\epsilon)$
can be bounded by $\sum_{i'=1}^n nd_{i'}$, which is
a integrable random variable. Thus, if we can prove
$X(l+\epsilon) \rightarrow X(l)$ almost surely
as $\epsilon \rightarrow 0$, the theorem will follow from
Dominated Convergence Theorem.

Now fix a sample path $\omega$. Consider the decision epoch for patient $i$.
Unless there are two sites with no patients assigned, there will almost surely
be a non-zero gap between the earliest completion time and the rest.
Let $g_1>0$ be the smallest such non-zero gap.

Consider the closest pair of decision epoch and moment when a scan
is finished in time, and let $g_2$ be the time between them.
Almost surely, $g_2 > 0$. We claim $X(l+\epsilon)=X(l)$,
if $|\epsilon| < \min\{g_1, g_2\}$,

Actually, we will prove the two systems will evolve exactly the same.
Suppose that on the contrary, the two systems diverge when
making decisions for patient $i$. Since $|\epsilon| < g_2$,
there is no scan completion between $\tilde a_i -l$ and
$\tilde a_i-\epsilon$, thus $P_{ij}(l) = P_{ij}(l+\epsilon)$ for any site $j$,
or the two systems see the same set of assigned patients.
The two system should both choose among the sites with no assigned patients
the one with lowest number, should such site exist.
Otherwise, because $|\epsilon| < g_1$, the site with lowest $C_{ij}(l)$
still has lowest $C_{ij}(l+\epsilon)$. The two systems still
make the same decision.

Thus, we have proved that the two system evolve
exactly the same when $\epsilon$ is sufficiently small.
This implies, $X(l+\epsilon) \rightarrow X(l)$ almost surely
when $\epsilon \rightarrow 0$. This completes our proof.
\end{proof}
